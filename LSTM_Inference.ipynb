{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af1b3fd4-6226-4ed3-bac4-bae9e7af5267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors  # Assuming you're using Word2Vec embeddings\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76435d72-2e19-4012-b0c3-bc8809869bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c52c7d-9ee2-4443-a595-f390fbf44851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_word_list(text):\n",
    "    ''' Pre process and convert texts to a list of words '''\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f5edec-87d7-4ebc-b81d-a6fcc8e87f47",
   "metadata": {},
   "source": [
    "### Checking the functionality of the loaded embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0da85bda-0c9d-4261-8016-38d2525b9e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load vocabulary and inverse vocabulary from saved files\n",
    "with open(r'products_weights_vocabs/vocabulary.pkl', 'rb') as f:\n",
    "    vocabulary = pickle.load(f)\n",
    "\n",
    "with open(r'products_weights_vocabs/inverse_vocabulary.pkl', 'rb') as f:\n",
    "    inverse_vocabulary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa81202-989a-453d-998f-50615ebb6f52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[\"bad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f08c6011-82a9-4804-8acb-4127c79f1340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58563"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "695c7e9a-7b53-42ab-bdb0-4f7c0da54b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q = [\"Why Is It Important To Get Life Insurance?\", \"What Makes Life Insurance Important?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2893ad38-6d45-4e4d-81d4-578fc818a5bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q_tokenized = [text_to_word_list(question) for question in Q]\n",
    "\n",
    "encoded_questions = []\n",
    "\n",
    "# Encode each question based on the vocabulary\n",
    "for question_tokens in Q_tokenized:\n",
    "    encoded_question = []\n",
    "    for token in question_tokens:\n",
    "        if token in vocabulary:\n",
    "            encoded_question.append(vocabulary[token])\n",
    "        elif token in stops:\n",
    "            continue\n",
    "        else:\n",
    "            encoded_question.append(0)  # Handle unknown words with '<unk>' index\n",
    "    encoded_questions.append(encoded_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f50761e-348a-4e9d-a45b-60067c86d6e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['why', 'is', 'it', 'important', 'to', 'get', 'life', 'insurance'],\n",
       " ['what', 'makes', 'life', 'insurance', 'important']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f72c3e9a-50b5-46fa-97fd-c48c9e1da8ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Questions:\n",
      "Question: Why Is It Important To Get Life Insurance?\n",
      "Encoded: [422, 264, 490, 2667]\n",
      "\n",
      "Question: What Makes Life Insurance Important?\n",
      "Encoded: [253, 490, 2667, 422]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoded Questions:\")\n",
    "for question, encoded in zip(Q, encoded_questions):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Encoded: {encoded}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f217fa0-5d76-4efb-a536-0164a5bb2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_question_1 = encoded_questions[0]\n",
    "encoded_question_2 = encoded_questions[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c40222-05a0-40af-aabd-cb36fc2ce22a",
   "metadata": {},
   "source": [
    "### Recreate model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3db08deb-2122-43a0-bf9c-3187b355f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfa4096c-088e-4b0c-b6f6-68cdc298c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = r\"products_weights_vocabs/train.csv\"\n",
    "TEST_CSV = r\"products_weights_vocabs/test.csv\"\n",
    "embeddings = np.load('products_weights_vocabs/embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e67c74-dfa2-4c95-a178-e5ccf0c21c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58564, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c54c345f-b0f9-4f02-a4ba-b15f74df0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 50\n",
    "gradient_clipping_norm = 1.25\n",
    "batch_size = 64\n",
    "n_epoch = 25\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6130fde3-cd5c-493d-9274-720d5d0d2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    return tf.math.exp(-tf.math.reduce_sum(tf.math.abs(left - right), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23a906bc-cec9-4f6d-b743-e49782c4365f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "# Create dummy data\n",
    "max_seq_length = 101  # Adjust based on your training\n",
    "input_left = Input(shape=(max_seq_length,))\n",
    "input_right = Input(shape=(max_seq_length,))\n",
    "\n",
    "left_output = tf.keras.layers.Dense(10)(input_left)\n",
    "right_output = tf.keras.layers.Dense(10)(input_right)\n",
    "\n",
    "distance_layer = Lambda(lambda x: exponent_neg_manhattan_distance(x[0], x[1]))([left_output, right_output])\n",
    "\n",
    "test_model = Model(inputs=[input_left, input_right], outputs=distance_layer)\n",
    "\n",
    "dummy_data_left = tf.constant([[0] * max_seq_length], dtype=tf.float32)\n",
    "dummy_data_right = tf.constant([[0] * max_seq_length], dtype=tf.float32)\n",
    "\n",
    "test_output = test_model.predict([dummy_data_left, dummy_data_right])\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e9b1941-72fe-429f-b3fe-4eb551f9e5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Korisnik\\envs\\chatbot2\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "embedding_dim = embeddings.shape[1]\n",
    "vocab_size = len(vocabulary)\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, embedding_dim, input_length=max_seq_length, trainable=False)\n",
    "\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n",
    "shared_lstm = LSTM(n_hidden, dropout=dropout_rate, recurrent_dropout=dropout_rate)\n",
    "\n",
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)\n",
    "\n",
    "malstm_distance = Lambda(lambda x: exponent_neg_manhattan_distance(x[0], x[1]))([left_output, right_output])\n",
    "\n",
    "malstm = Model([left_input, right_input], [malstm_distance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c60c4133-fa38-4bad-9d86-8ebd50135f1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A total of 1 objects could not be loaded. Example error message for object <Embedding name=embedding, built=True>:\n\nThe shape of the target variable and the shape of the target value in `variable.assign(value)` must match. variable.shape=(58563, 300), Received: value.shape=(49558, 300). Target variable: <KerasVariable shape=(58563, 300), dtype=float32, path=embedding/embeddings>\n\nList of objects that could not be loaded:\n[<Embedding name=embedding, built=True>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmalstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmalstm_weights.weights.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\envs\\chatbot2\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\envs\\chatbot2\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:456\u001b[0m, in \u001b[0;36m_raise_loading_failure\u001b[1;34m(error_msgs, warn_only)\u001b[0m\n\u001b[0;32m    454\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: A total of 1 objects could not be loaded. Example error message for object <Embedding name=embedding, built=True>:\n\nThe shape of the target variable and the shape of the target value in `variable.assign(value)` must match. variable.shape=(58563, 300), Received: value.shape=(49558, 300). Target variable: <KerasVariable shape=(58563, 300), dtype=float32, path=embedding/embeddings>\n\nList of objects that could not be loaded:\n[<Embedding name=embedding, built=True>]"
     ]
    }
   ],
   "source": [
    "malstm.load_weights(\"malstm_weights.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd295003-5dfd-460d-91b9-6f2b80d94762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.config.enable_unsafe_deserialization() # Custom func dodesnt work without deseralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef2f093f-30ca-4c52-b72d-07b3a69ed381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">14,867,400</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                               │                           │                 │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">70,200</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m, \u001b[38;5;34m300\u001b[0m)          │      \u001b[38;5;34m14,867,400\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                               │                           │                 │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                │          \u001b[38;5;34m70,200\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], lstm[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,007,802</span> (57.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,007,802\u001b[0m (57.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,200</span> (274.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,200\u001b[0m (274.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,867,400</span> (56.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,867,400\u001b[0m (56.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,202</span> (274.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m70,202\u001b[0m (274.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7b1aad0-8835-4f45-9b7a-3375ffdac8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 101)\n",
      "(1, 101)\n"
     ]
    }
   ],
   "source": [
    "print(padded_question_1.shape)\n",
    "print(padded_question_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5711226b-0d6c-4f9d-8e70-63cbc339af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([padded_question_1, padded_question_2])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d9e77-5ec5-484e-92e3-2fab7da53efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b7cd06-c2ff-467c-aba0-ca0778979045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
